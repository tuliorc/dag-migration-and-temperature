{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Capstone Project\n",
    "\n",
    "## Is there any correlation between the increase in the net migration rate and the average temperature change? \n",
    "\n",
    "\n",
    "To help data analysts in answering that question, this project is broken down into the following steps:\n",
    "\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries and function\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Spark session\n",
    "spark = SparkSession.builder.config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\").enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope \n",
    "This project aims at helping data analysts in answering if there is any correlation between the increase in the net migration rate and the average temperature change per city per year. Does the temperature increase when the corresponding city receives more immigrants than usual? We know that immigrants tend to travel back-and-forth to visit their families in their home country, whicht could lead to busier airports and more air pollution. Hence, there is a handful of variables to investigate: net migration rate, airport flow, air pollution and ratio of temperature change, all of which will be analysed per city per year.\n",
    "\n",
    "The end case is a source-of-truth database containing average temperature changes, demographics and immigration data per city per year, and also a set of analytical tables for further investigations. ETL scripts managed by DAGs are able to help in streaming the data from the original datasets to a single source-of-truth dataset; in a similar fashion, further DAG steps can assist in building the set of analytical tables.\n",
    "\n",
    "The aforementioned data sources are briefly described as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Airport Code Table:\n",
    "This is a simple table provided by Datahub containing airport codes and their corresponding cities. It includes the airport type, name, elevation in feets, country/region/municipality and coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports = pd.read_csv('airport-codes_csv.csv')\n",
    "df_airports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### U.S. City Demographic Data:\n",
    "This data was provided by OpenSoft. It includes the male/female/total population, overall median age, number of veterans and foreign-born per city, as well as the number of individuals in a given city/state per race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics = pd.read_csv('us-cities-demographics.csv', sep=\";\")\n",
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### World Temperature Data:\n",
    "This dataset was taken from Kaggle. It provides the average temperature and the average temperature uncertainty per date and city/country. It also includes more granular information like the latitude and longitude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temperature data\n",
    "df_temperatures = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "df_temperatures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I94 Immigration Data:\n",
    "This data comes from the US National Tourism and Trade Office. It provides data on the passenger level, including gender, visa type, year of birth, departure and arrival dates, flight airline, airport of arrival, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U     None   1979.0  10282016   None   None   \n",
       "1      NaN   ...           Y     None   1991.0       D/S      M   None   \n",
       "2  20691.0   ...        None        M   1961.0  09302016      M   None   \n",
       "3  20567.0   ...        None        M   1988.0  09302016   None   None   \n",
       "4  20567.0   ...        None        M   2012.0  09302016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0    None  1.897628e+09   None       B2  \n",
       "1    None  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df_immigration = spark.read.format('com.github.saurfang.sas.spark').load(fname)\n",
    "df_immigration.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Exploring and Assessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploratory_analysis(df):\n",
    "    \"\"\"\n",
    "    This function unravels each column of a given dataset, providing their percentage of unique and missing rows,\n",
    "    as well as the number of zeros.\n",
    "    In case the column is numerical, this function also provides maximum, minimum,\n",
    "    median and mean values for analysing the column's distribution.\n",
    "    \"\"\"\n",
    "    eda_df = {}\n",
    "    columns = df.columns\n",
    "    for column in columns:\n",
    "        eda_column = {}\n",
    "        eda_column['type'] = type(df[column][0])\n",
    "        eda_column['% unique'] = round(len(df[column].unique()) / len(df[column]) * 100, 2)\n",
    "        eda_column['% missing'] = round(len(df[df[column].isna()]) / len(df[column]) * 100, 2)\n",
    "        eda_column['% zeros'] = round(len(df[df[column] == 0]) / len(df[column]) * 100, 2)\n",
    "        if not isinstance(df[df[column].notna()][column].iloc[0], str):\n",
    "            eda_column['Max'] = df[column].fillna(0).max()\n",
    "            eda_column['Min'] = df[column].fillna(0).min()\n",
    "            eda_column['Median'] = df[column].fillna(0).median()\n",
    "            eda_column['Mean'] = df[column].fillna(0).mean()\n",
    "        else: \n",
    "            eda_column['Max'] = None\n",
    "            eda_column['Min'] = None\n",
    "            eda_column['Median'] = None\n",
    "            eda_column['Mean'] = None\n",
    "        eda_df[column] = eda_column\n",
    "    return pd.DataFrame(eda_df).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore each dataset column to see if any data cleaning is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airports Dataset\n",
    "Since we are going to explore air traffic in cities in the United States, we can begin the analysis by filtering out airports outside the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airports = df_airports[df_airports['iso_country'] == 'US']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for duplicated rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ident, type, name, elevation_ft, continent, iso_country, iso_region, municipality, gps_code, iata_code, local_code, coordinates]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports[df_airports.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicated rows were found, so we go further with the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% missing</th>\n",
       "      <th>% unique</th>\n",
       "      <th>% zeros</th>\n",
       "      <th>Max</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Min</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ident</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>0</td>\n",
       "      <td>93.36</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elevation_ft</th>\n",
       "      <td>1.05</td>\n",
       "      <td>16.65</td>\n",
       "      <td>0.26</td>\n",
       "      <td>12442</td>\n",
       "      <td>1139.11</td>\n",
       "      <td>731</td>\n",
       "      <td>-210</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continent</th>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'float'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iso_country</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iso_region</th>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>municipality</th>\n",
       "      <td>0.45</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gps_code</th>\n",
       "      <td>7.79</td>\n",
       "      <td>91.98</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iata_code</th>\n",
       "      <td>91.13</td>\n",
       "      <td>8.85</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'float'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_code</th>\n",
       "      <td>6.68</td>\n",
       "      <td>93.03</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coordinates</th>\n",
       "      <td>0</td>\n",
       "      <td>99.94</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             % missing % unique % zeros    Max     Mean Median   Min  \\\n",
       "ident                0      100       0   None     None   None  None   \n",
       "type                 0     0.03       0   None     None   None  None   \n",
       "name                 0    93.36       0   None     None   None  None   \n",
       "elevation_ft      1.05    16.65    0.26  12442  1139.11    731  -210   \n",
       "continent          100     0.01       0   None     None   None  None   \n",
       "iso_country          0        0       0   None     None   None  None   \n",
       "iso_region           0     0.23       0   None     None   None  None   \n",
       "municipality      0.45     38.4       0   None     None   None  None   \n",
       "gps_code          7.79    91.98       0   None     None   None  None   \n",
       "iata_code        91.13     8.85       0   None     None   None  None   \n",
       "local_code        6.68    93.03       0   None     None   None  None   \n",
       "coordinates          0    99.94       0   None     None   None  None   \n",
       "\n",
       "                                 type  \n",
       "ident                   <class 'str'>  \n",
       "type                    <class 'str'>  \n",
       "name                    <class 'str'>  \n",
       "elevation_ft  <class 'numpy.float64'>  \n",
       "continent             <class 'float'>  \n",
       "iso_country             <class 'str'>  \n",
       "iso_region              <class 'str'>  \n",
       "municipality            <class 'str'>  \n",
       "gps_code                <class 'str'>  \n",
       "iata_code             <class 'float'>  \n",
       "local_code              <class 'str'>  \n",
       "coordinates             <class 'str'>  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploratory_analysis(df_airports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seems that the only numerical columns here are the iata code and the continent. As we are analysing only the US, so the continent column is disposable. iata_code is missing in 91.13% missing rows, so it's also best to delete it.\n",
    "- The unique id (ident column) has no missing values, which is good. The coordinates seem to be unique as well: 99.64% of the rows have unique coordinates. We might need to delete the few ones that are not unique, though.  \n",
    "- type: only 0.03% unique values. Requires further investigation on the few rows that are not under common categories.\n",
    "- name: 93.96% unique values. Requires further investigation. \n",
    "- elevation_ft: distribution of values seems acceptable. We might investigate the 1.05% rows that have no elevation information.\n",
    "- iso_region: requires counting values under each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airports = df_airports[['ident', 'type', 'name', 'elevation_ft', 'iso_region', 'municipality', 'gps_code', 'local_code', 'coordinates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "type\n",
      "small_airport     60.289142\n",
      "heliport          27.529991\n",
      "closed             5.826779\n",
      "medium_airport     3.040823\n",
      "seaplane_base      2.487147\n",
      "large_airport      0.747023\n",
      "balloonport        0.079097\n",
      "Name: type, dtype: float64\n",
      "----------------------------\n",
      "----------------------------\n",
      "iso_region\n",
      "US-TX     10.005713\n",
      "US-CA      4.780947\n",
      "US-FL      4.249242\n",
      "US-PA      4.033924\n",
      "US-IL      3.963616\n",
      "US-AK      3.642835\n",
      "US-OH      3.511008\n",
      "US-IN      3.062794\n",
      "US-NY      2.935361\n",
      "US-WI      2.742013\n",
      "US-LA      2.601397\n",
      "US-WA      2.539878\n",
      "US-MO      2.539878\n",
      "US-MN      2.500330\n",
      "US-MI      2.412445\n",
      "US-OK      2.359713\n",
      "US-GA      2.293800\n",
      "US-CO      2.219097\n",
      "US-VA      2.219097\n",
      "US-OR      2.161972\n",
      "US-NC      2.078481\n",
      "US-NJ      1.942260\n",
      "US-KS      1.929077\n",
      "US-AR      1.784066\n",
      "US-AL      1.586325\n",
      "US-AZ      1.577537\n",
      "US-TN      1.564354\n",
      "US-IA      1.485257\n",
      "US-MT      1.454498\n",
      "US-ND      1.410555\n",
      "US-ID      1.384189\n",
      "US-NE      1.357824\n",
      "US-MS      1.234785\n",
      "US-MD      1.129323\n",
      "US-KY      1.129323\n",
      "US-MA      1.129323\n",
      "US-SC      0.953553\n",
      "US-SD      0.927187\n",
      "US-ME      0.914004\n",
      "US-NM      0.870062\n",
      "US-NH      0.786571\n",
      "US-UT      0.747023\n",
      "US-CT      0.720657\n",
      "US-NV      0.685503\n",
      "US-WV      0.615195\n",
      "US-WY      0.558070\n",
      "US-VT      0.448214\n",
      "US-HI      0.281232\n",
      "US-DE      0.250472\n",
      "US-RI      0.153799\n",
      "US-DC      0.092279\n",
      "US-U-A     0.043943\n",
      "Name: iso_region, dtype: float64\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for column in ['type', 'iso_region']:\n",
    "    print('----------------------------')\n",
    "    print(column)\n",
    "    print(df_airports[column].value_counts(normalize=True)*100)\n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, both airport types and regions seem acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02 % of the rows have \"0,0\" coordinates, which is unfortunate...\n"
     ]
    }
   ],
   "source": [
    "print(round(len(df_airports[df_airports['coordinates'] == '0, 0'])/len(df_airports)*100, 2), \n",
    "      '% of the rows have \"0,0\" coordinates, which is unfortunate...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... but these same rows have airport codes and iso_region, so we might still keep them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49820</th>\n",
       "      <td>US-0805</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Twin Cities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>Tabor City,NC</td>\n",
       "      <td>K5J9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0, 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49898</th>\n",
       "      <td>US-0883</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>JFK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0, 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49947</th>\n",
       "      <td>US-0932</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>CLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US-U-A</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0, 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>US-0984</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>0c2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US-IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0, 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50032</th>\n",
       "      <td>US-1016</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>JFK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US-NY</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0, 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ident           type         name  elevation_ft iso_region  \\\n",
       "49820  US-0805  small_airport  Twin Cities           NaN     US-U-A   \n",
       "49898  US-0883  large_airport          JFK           NaN      US-NY   \n",
       "49947  US-0932  small_airport          CLE           NaN     US-U-A   \n",
       "49999  US-0984  small_airport          0c2           NaN      US-IL   \n",
       "50032  US-1016  large_airport          JFK           NaN      US-NY   \n",
       "\n",
       "        municipality gps_code local_code coordinates  \n",
       "49820  Tabor City,NC     K5J9        NaN        0, 0  \n",
       "49898       New York      NaN        NaN        0, 0  \n",
       "49947      Cleveland      NaN        NaN        0, 0  \n",
       "49999            NaN      NaN        NaN        0, 0  \n",
       "50032  New York City      NaN        NaN        0, 0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports[df_airports['coordinates'] == '0, 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing up: to fulfill the project goals, in the airports dataset we should **filter out airports that are not inside the US** and **select only the following columns: 'ident', 'type', 'name', 'elevation_ft', 'iso_region', 'municipality', 'gps_code', 'local_code', 'coordinates'**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for duplicated rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [City, State, Median Age, Male Population, Female Population, Total Population, Number of Veterans, Foreign-born, Average Household Size, State Code, Race, Count]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics[df_demographics.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicated rows were found, so we go further with the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% missing</th>\n",
       "      <th>% unique</th>\n",
       "      <th>% zeros</th>\n",
       "      <th>Max</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Min</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>0</td>\n",
       "      <td>19.61</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median Age</th>\n",
       "      <td>0</td>\n",
       "      <td>6.23</td>\n",
       "      <td>0</td>\n",
       "      <td>70.5</td>\n",
       "      <td>35.4949</td>\n",
       "      <td>35.3</td>\n",
       "      <td>22.9</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male Population</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20.55</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0817e+06</td>\n",
       "      <td>97227.4</td>\n",
       "      <td>52336</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female Population</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20.58</td>\n",
       "      <td>0</td>\n",
       "      <td>4.46871e+06</td>\n",
       "      <td>101664</td>\n",
       "      <td>53809</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Population</th>\n",
       "      <td>0</td>\n",
       "      <td>20.55</td>\n",
       "      <td>0</td>\n",
       "      <td>8550405</td>\n",
       "      <td>198967</td>\n",
       "      <td>106782</td>\n",
       "      <td>63215</td>\n",
       "      <td>&lt;class 'numpy.int64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Veterans</th>\n",
       "      <td>0.45</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0</td>\n",
       "      <td>156961</td>\n",
       "      <td>9325.71</td>\n",
       "      <td>5394</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foreign-born</th>\n",
       "      <td>0.45</td>\n",
       "      <td>20.34</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2125e+06</td>\n",
       "      <td>40470.8</td>\n",
       "      <td>18666</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Household Size</th>\n",
       "      <td>0.55</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.98</td>\n",
       "      <td>2.72736</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State Code</th>\n",
       "      <td>0</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race</th>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>0</td>\n",
       "      <td>96.33</td>\n",
       "      <td>0</td>\n",
       "      <td>3835726</td>\n",
       "      <td>48963.8</td>\n",
       "      <td>13780</td>\n",
       "      <td>98</td>\n",
       "      <td>&lt;class 'numpy.int64'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       % missing % unique % zeros          Max     Mean  \\\n",
       "City                           0    19.61       0         None     None   \n",
       "State                          0     1.69       0         None     None   \n",
       "Median Age                     0     6.23       0         70.5  35.4949   \n",
       "Male Population              0.1    20.55       0   4.0817e+06  97227.4   \n",
       "Female Population            0.1    20.58       0  4.46871e+06   101664   \n",
       "Total Population               0    20.55       0      8550405   198967   \n",
       "Number of Veterans          0.45    19.99       0       156961  9325.71   \n",
       "Foreign-born                0.45    20.34       0   3.2125e+06  40470.8   \n",
       "Average Household Size      0.55      5.6       0         4.98  2.72736   \n",
       "State Code                     0     1.69       0         None     None   \n",
       "Race                           0     0.17       0         None     None   \n",
       "Count                          0    96.33       0      3835726  48963.8   \n",
       "\n",
       "                        Median    Min                     type  \n",
       "City                      None   None            <class 'str'>  \n",
       "State                     None   None            <class 'str'>  \n",
       "Median Age                35.3   22.9  <class 'numpy.float64'>  \n",
       "Male Population          52336      0  <class 'numpy.float64'>  \n",
       "Female Population        53809      0  <class 'numpy.float64'>  \n",
       "Total Population        106782  63215    <class 'numpy.int64'>  \n",
       "Number of Veterans        5394      0  <class 'numpy.float64'>  \n",
       "Foreign-born             18666      0  <class 'numpy.float64'>  \n",
       "Average Household Size    2.65      0  <class 'numpy.float64'>  \n",
       "State Code                None   None            <class 'str'>  \n",
       "Race                      None   None            <class 'str'>  \n",
       "Count                    13780     98    <class 'numpy.int64'>  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploratory_analysis(df_demographics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All numerical variables (age, population, # veterans, # foreign born, # average household size) show a logical distribution.\n",
    "\n",
    "Average Household Size and number of veterans have lots of missing values, but those columns won't be useful for our analysis, so we can just dispose of them. As for the foreign-born column, it requires further investigation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics = df_demographics[['City', 'State', 'Median Age', 'Male Population', 'Female Population',\n",
    "                                   'Total Population', 'Foreign-born', 'State Code', 'Race', 'Count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As also seen above, the city column seems to be quite repetitive along the rows, so let's investigate it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Race</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abilene</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Akron</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alafaya</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alameda</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albany</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Race\n",
       "City         \n",
       "Abilene     5\n",
       "Akron       5\n",
       "Alafaya     4\n",
       "Alameda     5\n",
       "Albany     10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics.groupby('City')[['Race']].count().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some cities appear 5 times in the dataset, some 4 times, some even 10... as seen below, we have 5 different races in the dataset, so probably each city has 1 row per race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hispanic or Latino                   596\n",
       "White                                589\n",
       "Black or African-American            584\n",
       "Asian                                583\n",
       "American Indian and Alaska Native    539\n",
       "Name: Race, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics['Race'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of Alafaya, there's no statistics for the American Indian and Alaska Native population, whereas there's 2 cities named Albany in the US, as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Alafaya</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33.5</td>\n",
       "      <td>39504.0</td>\n",
       "      <td>45760.0</td>\n",
       "      <td>85264</td>\n",
       "      <td>15842.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>63666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>Alafaya</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33.5</td>\n",
       "      <td>39504.0</td>\n",
       "      <td>45760.0</td>\n",
       "      <td>85264</td>\n",
       "      <td>15842.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>10336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>Alafaya</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33.5</td>\n",
       "      <td>39504.0</td>\n",
       "      <td>45760.0</td>\n",
       "      <td>85264</td>\n",
       "      <td>15842.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>34897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>Alafaya</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33.5</td>\n",
       "      <td>39504.0</td>\n",
       "      <td>45760.0</td>\n",
       "      <td>85264</td>\n",
       "      <td>15842.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>6577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City    State  Median Age  Male Population  Female Population  \\\n",
       "135   Alafaya  Florida        33.5          39504.0            45760.0   \n",
       "554   Alafaya  Florida        33.5          39504.0            45760.0   \n",
       "793   Alafaya  Florida        33.5          39504.0            45760.0   \n",
       "1868  Alafaya  Florida        33.5          39504.0            45760.0   \n",
       "\n",
       "      Total Population  Foreign-born State Code                       Race  \\\n",
       "135              85264       15842.0         FL                      White   \n",
       "554              85264       15842.0         FL                      Asian   \n",
       "793              85264       15842.0         FL         Hispanic or Latino   \n",
       "1868             85264       15842.0         FL  Black or African-American   \n",
       "\n",
       "      Count  \n",
       "135   63666  \n",
       "554   10336  \n",
       "793   34897  \n",
       "1868   6577  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics[df_demographics['City'] == 'Alafaya']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>33.3</td>\n",
       "      <td>31695.0</td>\n",
       "      <td>39414.0</td>\n",
       "      <td>71109</td>\n",
       "      <td>861.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>33.3</td>\n",
       "      <td>31695.0</td>\n",
       "      <td>39414.0</td>\n",
       "      <td>71109</td>\n",
       "      <td>861.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>White</td>\n",
       "      <td>17160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>32.8</td>\n",
       "      <td>47627.0</td>\n",
       "      <td>50825.0</td>\n",
       "      <td>98452</td>\n",
       "      <td>11948.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>33.3</td>\n",
       "      <td>31695.0</td>\n",
       "      <td>39414.0</td>\n",
       "      <td>71109</td>\n",
       "      <td>861.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>32.8</td>\n",
       "      <td>47627.0</td>\n",
       "      <td>50825.0</td>\n",
       "      <td>98452</td>\n",
       "      <td>11948.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>9368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>32.8</td>\n",
       "      <td>47627.0</td>\n",
       "      <td>50825.0</td>\n",
       "      <td>98452</td>\n",
       "      <td>11948.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>White</td>\n",
       "      <td>58368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>33.3</td>\n",
       "      <td>31695.0</td>\n",
       "      <td>39414.0</td>\n",
       "      <td>71109</td>\n",
       "      <td>861.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>53440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>32.8</td>\n",
       "      <td>47627.0</td>\n",
       "      <td>50825.0</td>\n",
       "      <td>98452</td>\n",
       "      <td>11948.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>31303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>Albany</td>\n",
       "      <td>New York</td>\n",
       "      <td>32.8</td>\n",
       "      <td>47627.0</td>\n",
       "      <td>50825.0</td>\n",
       "      <td>98452</td>\n",
       "      <td>11948.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>Asian</td>\n",
       "      <td>8090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>Albany</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>33.3</td>\n",
       "      <td>31695.0</td>\n",
       "      <td>39414.0</td>\n",
       "      <td>71109</td>\n",
       "      <td>861.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City     State  Median Age  Male Population  Female Population  \\\n",
       "1165  Albany   Georgia        33.3          31695.0            39414.0   \n",
       "1260  Albany   Georgia        33.3          31695.0            39414.0   \n",
       "1470  Albany  New York        32.8          47627.0            50825.0   \n",
       "1616  Albany   Georgia        33.3          31695.0            39414.0   \n",
       "1809  Albany  New York        32.8          47627.0            50825.0   \n",
       "2000  Albany  New York        32.8          47627.0            50825.0   \n",
       "2050  Albany   Georgia        33.3          31695.0            39414.0   \n",
       "2278  Albany  New York        32.8          47627.0            50825.0   \n",
       "2472  Albany  New York        32.8          47627.0            50825.0   \n",
       "2552  Albany   Georgia        33.3          31695.0            39414.0   \n",
       "\n",
       "      Total Population  Foreign-born State Code  \\\n",
       "1165             71109         861.0         GA   \n",
       "1260             71109         861.0         GA   \n",
       "1470             98452       11948.0         NY   \n",
       "1616             71109         861.0         GA   \n",
       "1809             98452       11948.0         NY   \n",
       "2000             98452       11948.0         NY   \n",
       "2050             71109         861.0         GA   \n",
       "2278             98452       11948.0         NY   \n",
       "2472             98452       11948.0         NY   \n",
       "2552             71109         861.0         GA   \n",
       "\n",
       "                                   Race  Count  \n",
       "1165  American Indian and Alaska Native    445  \n",
       "1260                              White  17160  \n",
       "1470  American Indian and Alaska Native   1611  \n",
       "1616                              Asian    650  \n",
       "1809                 Hispanic or Latino   9368  \n",
       "2000                              White  58368  \n",
       "2050          Black or African-American  53440  \n",
       "2278          Black or African-American  31303  \n",
       "2472                              Asian   8090  \n",
       "2552                 Hispanic or Latino   1783  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics[df_demographics['City'] == 'Albany']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that this is clear, we analyse the missing values in population columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>72211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City    State  Median Age  Male Population  Female Population  \\\n",
       "333   The Villages  Florida        70.5              NaN                NaN   \n",
       "449   The Villages  Florida        70.5              NaN                NaN   \n",
       "1437  The Villages  Florida        70.5              NaN                NaN   \n",
       "\n",
       "      Total Population  Foreign-born State Code                       Race  \\\n",
       "333              72590        4034.0         FL         Hispanic or Latino   \n",
       "449              72590        4034.0         FL  Black or African-American   \n",
       "1437             72590        4034.0         FL                      White   \n",
       "\n",
       "      Count  \n",
       "333    1066  \n",
       "449     331  \n",
       "1437  72211  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics[df_demographics['Male Population'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>The Villages</td>\n",
       "      <td>Florida</td>\n",
       "      <td>70.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72590</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>72211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City    State  Median Age  Male Population  Female Population  \\\n",
       "333   The Villages  Florida        70.5              NaN                NaN   \n",
       "449   The Villages  Florida        70.5              NaN                NaN   \n",
       "1437  The Villages  Florida        70.5              NaN                NaN   \n",
       "\n",
       "      Total Population  Foreign-born State Code                       Race  \\\n",
       "333              72590        4034.0         FL         Hispanic or Latino   \n",
       "449              72590        4034.0         FL  Black or African-American   \n",
       "1437             72590        4034.0         FL                      White   \n",
       "\n",
       "      Count  \n",
       "333    1066  \n",
       "449     331  \n",
       "1437  72211  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics[df_demographics['Female Population'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although these rows have no information on male and female population, we can keep those because they have data on the total population, which per se is useful when calculatin the foreign-born percentage. As for the rows missing data in the foreign-born column, these should be removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics = df_demographics[~df_demographics['Foreign-born'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% missing</th>\n",
       "      <th>% unique</th>\n",
       "      <th>% zeros</th>\n",
       "      <th>Max</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Min</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>0</td>\n",
       "      <td>19.46</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median Age</th>\n",
       "      <td>0</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0</td>\n",
       "      <td>70.5</td>\n",
       "      <td>35.4712</td>\n",
       "      <td>35.3</td>\n",
       "      <td>22.9</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male Population</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0817e+06</td>\n",
       "      <td>97343.4</td>\n",
       "      <td>52336</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female Population</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20.43</td>\n",
       "      <td>0</td>\n",
       "      <td>4.46871e+06</td>\n",
       "      <td>101741</td>\n",
       "      <td>53809</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Population</th>\n",
       "      <td>0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0</td>\n",
       "      <td>8550405</td>\n",
       "      <td>199160</td>\n",
       "      <td>106782</td>\n",
       "      <td>63215</td>\n",
       "      <td>&lt;class 'numpy.int64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foreign-born</th>\n",
       "      <td>0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2125e+06</td>\n",
       "      <td>40653.6</td>\n",
       "      <td>18822</td>\n",
       "      <td>861</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State Code</th>\n",
       "      <td>0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Race</th>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>0</td>\n",
       "      <td>96.35</td>\n",
       "      <td>0</td>\n",
       "      <td>3835726</td>\n",
       "      <td>48838.4</td>\n",
       "      <td>13778</td>\n",
       "      <td>98</td>\n",
       "      <td>&lt;class 'numpy.int64'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  % missing % unique % zeros          Max     Mean  Median  \\\n",
       "City                      0    19.46       0         None     None    None   \n",
       "State                     0     1.67       0         None     None    None   \n",
       "Median Age                0     6.15       0         70.5  35.4712    35.3   \n",
       "Male Population         0.1     20.4       0   4.0817e+06  97343.4   52336   \n",
       "Female Population       0.1    20.43       0  4.46871e+06   101741   53809   \n",
       "Total Population          0     20.4       0      8550405   199160  106782   \n",
       "Foreign-born              0     20.4       0   3.2125e+06  40653.6   18822   \n",
       "State Code                0     1.67       0         None     None    None   \n",
       "Race                      0     0.17       0         None     None    None   \n",
       "Count                     0    96.35       0      3835726  48838.4   13778   \n",
       "\n",
       "                     Min                     type  \n",
       "City                None            <class 'str'>  \n",
       "State               None            <class 'str'>  \n",
       "Median Age          22.9  <class 'numpy.float64'>  \n",
       "Male Population        0  <class 'numpy.float64'>  \n",
       "Female Population      0  <class 'numpy.float64'>  \n",
       "Total Population   63215    <class 'numpy.int64'>  \n",
       "Foreign-born         861  <class 'numpy.float64'>  \n",
       "State Code          None            <class 'str'>  \n",
       "Race                None            <class 'str'>  \n",
       "Count                 98    <class 'numpy.int64'>  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploratory_analysis(df_demographics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing up: to fulfill the project goals, the demographics dataset should contain only rows with information on the foreign-born population and **display only the following columns: 'City', 'State', 'Median Age', 'Male Population', 'Female Population', 'Total Population', 'Foreign-born', 'State Code', 'Race', 'Count'**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperatures Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for duplicated rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [dt, AverageTemperature, AverageTemperatureUncertainty, City, Country, Latitude, Longitude]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperatures[df_temperatures.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicated rows were found, so we go further with the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% missing</th>\n",
       "      <th>% unique</th>\n",
       "      <th>% zeros</th>\n",
       "      <th>Max</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Min</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AverageTemperature</th>\n",
       "      <td>4.23</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.651</td>\n",
       "      <td>16.0191</td>\n",
       "      <td>18.204</td>\n",
       "      <td>-42.704</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <td>4.23</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0</td>\n",
       "      <td>15.396</td>\n",
       "      <td>0.98502</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longitude</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              % missing % unique % zeros     Max     Mean  \\\n",
       "dt                                    0     0.04       0    None     None   \n",
       "AverageTemperature                 4.23      1.3       0  39.651  16.0191   \n",
       "AverageTemperatureUncertainty      4.23     0.13       0  15.396  0.98502   \n",
       "City                                  0     0.04       0    None     None   \n",
       "Country                               0        0       0    None     None   \n",
       "Latitude                              0        0       0    None     None   \n",
       "Longitude                             0     0.01       0    None     None   \n",
       "\n",
       "                               Median     Min                     type  \n",
       "dt                               None    None            <class 'str'>  \n",
       "AverageTemperature             18.204 -42.704  <class 'numpy.float64'>  \n",
       "AverageTemperatureUncertainty   0.557       0  <class 'numpy.float64'>  \n",
       "City                             None    None            <class 'str'>  \n",
       "Country                          None    None            <class 'str'>  \n",
       "Latitude                         None    None            <class 'str'>  \n",
       "Longitude                        None    None            <class 'str'>  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploratory_analysis(df_temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The date (dt) column is quite repetitive in this dataset, which makes sense, as it displays average temperatures for each city for each date. \n",
    "* 4.23% of Average Temperature and Average Temperature Uncertainty columns have missing values, so it's best to drop those. \n",
    "* Once again, we're gonna filter out all rows that are not related to cities in the US. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the line below, we're selecting US cities and deleting missing values at the same time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temperatures = df_temperatures[df_temperatures['Country'] == 'United States'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing up: to fulfill the project goals, the temperatures dataset **should not contain rows with missing values** and it **should include only US cities**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immigration Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyspark allows us to drop duplicate rows in a straightforward fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration = df_immigration.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all of the columns are relevant for the scope of this project, so let's select a subset of the data and also rename the columns to more meaningful and intuitive names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration = df_immigration.selectExpr(['i94yr as i94_year', 'i94mon as i94_month', 'i94cit as city_origin',\n",
    "                                            'i94res as city_destination', 'i94port as airport_code', 'arrdate as arrival_date',\n",
    "                                            'depdate as departure_date', 'i94visa as i94_visa', 'visatype as visa_type', 'biryear as year_birth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The immigration dataset is very large, so before converting it to Pandas we can benefit by taking a small sample from it. As seen below, we are taking a 20% sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration_sample = df_immigration.sample(False, 0.2, 42).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% missing</th>\n",
       "      <th>% unique</th>\n",
       "      <th>% zeros</th>\n",
       "      <th>Max</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Min</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i94_year</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94_month</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_origin</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>304.869</td>\n",
       "      <td>213</td>\n",
       "      <td>101</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_destination</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>749</td>\n",
       "      <td>303.245</td>\n",
       "      <td>213</td>\n",
       "      <td>101</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airport_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20574</td>\n",
       "      <td>20559.8</td>\n",
       "      <td>20560</td>\n",
       "      <td>20545</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>departure_date</th>\n",
       "      <td>4.61</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>45427</td>\n",
       "      <td>19626</td>\n",
       "      <td>20569</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94_visa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.84505</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visa_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_birth</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1973.74</td>\n",
       "      <td>1975</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 % missing % unique % zeros    Max     Mean Median    Min  \\\n",
       "i94_year                 0        0       0   2016     2016   2016   2016   \n",
       "i94_month                0        0       0      4        4      4      4   \n",
       "city_origin              0     0.04       0    999  304.869    213    101   \n",
       "city_destination         0     0.04       0    749  303.245    213    101   \n",
       "airport_code             0     0.04       0   None     None   None   None   \n",
       "arrival_date             0        0       0  20574  20559.8  20560  20545   \n",
       "departure_date        4.61     0.03       0  45427    19626  20569      0   \n",
       "i94_visa                 0        0       0      3  1.84505      2      1   \n",
       "visa_type                0        0       0   None     None   None   None   \n",
       "year_birth            0.03     0.02       0   2019  1973.74   1975      0   \n",
       "\n",
       "                                     type  \n",
       "i94_year          <class 'numpy.float64'>  \n",
       "i94_month         <class 'numpy.float64'>  \n",
       "city_origin       <class 'numpy.float64'>  \n",
       "city_destination  <class 'numpy.float64'>  \n",
       "airport_code                <class 'str'>  \n",
       "arrival_date      <class 'numpy.float64'>  \n",
       "departure_date    <class 'numpy.float64'>  \n",
       "i94_visa          <class 'numpy.float64'>  \n",
       "visa_type                   <class 'str'>  \n",
       "year_birth        <class 'numpy.float64'>  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploratory_analysis(df_immigration_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the column of departure date is missing values in 4% of the cases, so it's best to remove those cases because this is an important column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_immigration = df_immigration.dropna(subset=('departure_date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% missing</th>\n",
       "      <th>% unique</th>\n",
       "      <th>% zeros</th>\n",
       "      <th>Max</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Min</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i94_year</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94_month</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_origin</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>303.438</td>\n",
       "      <td>213</td>\n",
       "      <td>101</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_destination</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>760</td>\n",
       "      <td>301.863</td>\n",
       "      <td>213</td>\n",
       "      <td>101</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airport_code</th>\n",
       "      <td>0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>20574</td>\n",
       "      <td>20559.8</td>\n",
       "      <td>20560</td>\n",
       "      <td>20545</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>departure_date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>45427</td>\n",
       "      <td>20574</td>\n",
       "      <td>20570</td>\n",
       "      <td>19095</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i94_visa</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.83804</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visa_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_birth</th>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1974.38</td>\n",
       "      <td>1975</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 % missing % unique % zeros    Max     Mean Median    Min  \\\n",
       "i94_year                 0        0       0   2016     2016   2016   2016   \n",
       "i94_month                0        0       0      4        4      4      4   \n",
       "city_origin              0     0.04       0    999  303.438    213    101   \n",
       "city_destination         0     0.04       0    760  301.863    213    101   \n",
       "airport_code             0     0.04       0   None     None   None   None   \n",
       "arrival_date             0     0.01       0  20574  20559.8  20560  20545   \n",
       "departure_date           0     0.03       0  45427    20574  20570  19095   \n",
       "i94_visa                 0        0       0      3  1.83804      2      1   \n",
       "visa_type                0        0       0   None     None   None   None   \n",
       "year_birth               0     0.02       0   2016  1974.38   1975      0   \n",
       "\n",
       "                                     type  \n",
       "i94_year          <class 'numpy.float64'>  \n",
       "i94_month         <class 'numpy.float64'>  \n",
       "city_origin       <class 'numpy.float64'>  \n",
       "city_destination  <class 'numpy.float64'>  \n",
       "airport_code                <class 'str'>  \n",
       "arrival_date      <class 'numpy.float64'>  \n",
       "departure_date    <class 'numpy.float64'>  \n",
       "i94_visa          <class 'numpy.float64'>  \n",
       "visa_type                   <class 'str'>  \n",
       "year_birth        <class 'numpy.float64'>  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immigration_sample = df_immigration.sample(False, 0.2, 42).toPandas()\n",
    "exploratory_analysis(df_immigration_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our sample is clean of missing values and duplicated rows. Cities, airports and dates are naturally repetitive in the immigration dataset, so the aforementioned % of unique values for these columns is acceptable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing up: to fulfill the project goals, the immigration dataset should **display only the following renamed columns: 'i94yr aka i94_year', 'i94mon aka i94_month', 'i94cit aka city_origin', 'i94res aka city_destination', 'i94port aka airport_code', 'arrdate aka arrival_date', 'depdate aka departure_date', 'i94visa aka i94_visa', 'visatype aka visa_type', and 'biryear aka year_birth'.**\n",
    "\n",
    "Also, **rows with no departure date should be removed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the Data Model\n",
    "### 3.1 Conceptual Data Model\n",
    "The purpose of this project is to find out whether the net migration rate exerts influence on the average temperature per city per year. Note that if a city receives an increasingly higher amount of immigrants in a year, the average temperature would not not be affected instantly, hence it's necessary to have years of temperature statistics at our disposal. \n",
    "\n",
    "The first transformation we are going to do is to get monthly average temperatures from the original temperatures dataset, which used to display temperatures for exact dates. The result dim_weather table is going to be partitioned by year/month.\n",
    "* **dim_weather**: *year, month*, city, average_monthly_temperature\n",
    "\n",
    "Secondly, we are going to build a table with demographics data indexed by city. For the purpose of this project, we don't need the race and male/female population data, but just the foreign born and total population instead. Median age might also be useful, so we'll keep that one.\n",
    "* **dim_cities**: *city*, state_code, total_population, median_age, foreign_born\n",
    "\n",
    "Then, we will have a fact table for each migration, containing information on the source and destination cities, airport of arrival, timestamps, and passenger's visa type, all specified by year/month/day.\n",
    "* **fact_migration**: *year_arrival, month_arrival, day_arrival*, city_origin_id, city_destination_id, airport_code, visa_type, \n",
    "\n",
    "Finally, we can build the desired calculations table based on the previous tables. This one will aggregate the amount of emigrants and immigrants as well as the average temperature per city, partitioned by year/month.\n",
    "* **calc_stats_migration**: *year, month*, city_id, amount_immigrants, amount_emmigrants, average_temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The Data Model Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to achieve a star schema like the one above, the data pipeline jobs must follow the steps below:\n",
    "\n",
    "1. Load CSV data (airports, demographics, temperature) and SAS data (immigration)\n",
    "\n",
    "2. Data cleaning: select only the columns useful for fulfilling the project's purpose\n",
    "\n",
    "3. Data cleaning: drop duplicates and missing values when required\n",
    "\n",
    "4. Data cleaning: filter out rows with information unrelated to US migration\n",
    "\n",
    "5. Data storage: put the resulting data in S3 for backup\n",
    "\n",
    "6. Data transformation: create star schema tables in Redshift\n",
    "\n",
    "7. Data transformation: load transformed data into dim/fact tables in Redshift\n",
    "\n",
    "8. Data integrity: run data quality checks both in the raw tables and in the star schema tables\n",
    "\n",
    "9. Data analysis: query star schema tables and test initial hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Pipelines to Model the Data \n",
    "### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting data pipeline follow the steps mentioned in 3.2 and looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](capstone_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Quality Checks\n",
    "\n",
    "The jobs responsible for running data quality checks are called run_staging_quality_checks and run_schema_quality_checks, both counting rows to ensure that the created tables are populated as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Data dictionary \n",
    "\n",
    "* The **dim_weather** table comprises information from the temperatures dataset, in which each row contains basically the average temperature for a city in a given month/year.\n",
    "\n",
    "* The **dim_cities** table comprises information from the demographics dataset, in which each row contains basically the city identifier and its corresponding state code, and also its total population, amount of foreign born people and the median age. The total population can be useful for when a data analyst should want to calculate the percentage of foreign-born people out of the total population for a given city. \n",
    "\n",
    "* The **fact_migration** table is a subset of the huge SAS migration dataset, containing a selection of columns useful for the purpose of this project: date of arrival (broken down into 3 columns: year_arrival, month_arrival, day_arrival), and also the city of origin, city of destination, airport code and visa type. \n",
    "\n",
    "* Last but not least, the **calc_stats_migration** table contains data provenient from the previous tables, so it should be the last one to be ingested. It sums up the amount of immigratns and emmigrants per city (which comes from the fact_migration table) and also the average_temperature for that very same given city (which comes from the dim_temperatures table) all grouped by year and month. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Conclusion\n",
    "\n",
    "The Big Data tools chosen for the purpose of this project are S3 and Redshift. Under the hood, the work has been done with Spark and Airflow.\n",
    "* The files are initially stored locally, which is not 100% safe; for that reason, the early steps in the pipeline aim at reading the SAS and CSV files and writing them in a S3 bucket to be safely stored and accessed by other teams in the company. Spark helps in that matter by reading the files, manipulating them and sending them to the cloud in an efficient fashion.\n",
    "* However, as it is known, dealing with raw data is still unefficient; for that very same reason, a star schema has been built in a Redshift cluster, which is fed with data coming from the raw tables in S3. There's no problem if the raw data volume increases, because the star schema tables won't be recreated; the new data will be appended to them instead.\n",
    "* Airflow was a very important tool during the development of this data pipeline, as it has orchestrated every and each step - conveniently allowing me to debug each job - and also scheduling the DAG to run every morning at 7am.\n",
    "\n",
    "**Final considerations**:\n",
    "* if the original data was to be increased by 100x, the files should not be in the desktop in the first place, but directly stored in S3 or should be read from their source via an API. This reading task should be added at the very beginning of the DAG. \n",
    "* if the data was to be queried by 100+ people, Athena could be a convenient tool for everyone to query the star schema in AWS. In order for the queries to be faster, gathering the most common requests among teammates should help in determining \"low hanging KPIs\" and creating new tables with even more digested data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
